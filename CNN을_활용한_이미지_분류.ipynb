{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN을 활용한 이미지 분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9Wzy+8g2wSUHVqKG63UXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tajyu/TensorFlow-Tutotrial/blob/main/CNN%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCz2S0hIuo1D"
      },
      "source": [
        "# **CNN**이란 원본 이니지의 각 픽셀을 포함한 주변 픽셀과 필터의 모든 픽셀을 각각 곱연산을 하고, 그 결과를 합해서 새로운 이미지에 넣어준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXmLhAYzu9ea"
      },
      "source": [
        "## 크게 2가지로 나눌수있으며,\n",
        "## ① Feature Extractor: 특징 정보를 추출하며, Convolution Layers + Pooling Layers해서 사용\n",
        "## ② Classifier(분류): Fully Connected Layers = Dense Layers + Dropout Layers로 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi6tNNCvvyjy"
      },
      "source": [
        "## - Convolution Layers: Input image에서 특징을 추출하는 역할\n",
        "## - Pooling Layers: 중요한 정보만 남기고 계산 부담을 줄여주는 역할\n",
        "## - Dropout Layers: 과적합을 방지하는 역할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9wasjc2yvxi"
      },
      "source": [
        "## Convolution Layer\n",
        "### - 컨볼루션 연산을 하는 레이어 (필터를 자동으로 추출한다.)\n",
        "## -----------------------------------------------------------------------------------\n",
        "### ex) layers.Conv2D(kernel_size = (3, 3), strides = (2, 2), padding = \"valid\", fiters = 16\n",
        "### - kernel_size: 필터 행렬의 크기\n",
        "### - strides: 필터 한 스텝 이동하는 크기 ex) (1,1), (2, 2), ...\n",
        "### - padding: 이미지 주변에 빈 값을 넣을지 지정하는 옵션 \n",
        "### -> \"valid(빈 값 사용X)\"와 \"same(빈 값 사용O => 0으로 쓰는경우 zero padding)\"\n",
        "### - filter: 필터의 개수 (너무 많으면 학습 속도가 느려질 수 있고, 과적합 발생 할 수도 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouGuFU9m1Pft"
      },
      "source": [
        "## CNN에서 유명한 필터:\n",
        "### - VGG: 네트워크가 깊어질수록 필터 2배씩 증가 ex) (64 -> 128 -> 256 -> 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64yZqVh40mRO"
      },
      "source": [
        "## Pooling Layer\n",
        "## - 이미지 크기를 줄이면서 중요한 정보만 남기기 위해서 subsampling하는 기법\n",
        "## -> 계산할 정보가 줄어서 오버피팅을 방지한다.\n",
        "### ----------------------------------------------------------------------------------------------\n",
        "### - Average Pooling\n",
        "### - Max Pooling\n",
        "### ex) layers.MaxPool2D(pool_size = (2,2), strides = (2, 2))\n",
        "### - pool_size: (2, 2) 행렬 안에서 최댓값만 남긴다.\n",
        "### - strides: 컨볼루션과 마찬가지로 한 스텝마다 이동하는 크기\n",
        "### -> 위 옵션으로 사용하면 이미지크기가 절반으로 줄어든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN_LLojL2IjQ"
      },
      "source": [
        "## Dense Layer\n",
        "### ex) layers.Dense(unit = 정수, activation = \"relu or softmax ...\", None)  \n",
        "### ex) layers.Dense(unit = 정수, activation = \"relu or softmax ...\", input_shape(x, y, z) ...)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg5pZjzn2ygW"
      },
      "source": [
        "## Dropout Layer\n",
        "### - 네트워크의 오버피팅을 막기위해 사용.\n",
        "### - 학습과정에서 무작위로 뉴런의 부분집합을 제거\n",
        "### - 학습과정에서는 확률적으로 일부 뉴런 연결을 끊고, 테스트시에는 모든 값을  포함해서 계산한다.\n",
        "### ex) layers.Dropout(rate = 0.3)\n",
        "### - rate: 제외할 뉴런의 비율"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7KzKueOwQw1"
      },
      "source": [
        "## Inputs -> Convolution -> Pooling -> Dense -> ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KN3hF8AWnvN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgXnG-njX8ep"
      },
      "source": [
        "## MNIST 데이세트 다운로드하고 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-tgfVe1ZCcS6",
        "outputId": "2c0f1fdc-83e7-40a1-ac2e-a96c1c47577c"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(train_images[7])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX-kgpsWwpmt"
      },
      "source": [
        "## reshape을 써야하는 이유: 데이터를 구성하는 이미지가 흑백(1채널), RGB(3채널)을 가지도록 데이터 shape으로 변경해줘야함.\n",
        "## 아래는 MNIST 데이터로 흑백 이미지라서 마지막에 **\"1\"**로 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YOTp1-AXN3m"
      },
      "source": [
        "# Conv2D 채널을 가진 형태로 변경을 해야 한다.\n",
        "# 데이터를 구성하는 이미지의 형태별로 마지막 값이 변경된다.(1 (흑백) or 3 (칼라))\n",
        "# 이미지의 형태에 맞도록 채널을 가지게 하기위하여 데이터 shape을 변경 해야해서 \"reshape\"을 한다.\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# 픽셀 값을 0 ~ 1 사이로 정규화한다.\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0 # 0 ~ 255 사이에 값이 있기 떄문에 255.0 으로 나누어 0 ~ 1로 바꿔준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5NdqxhAx1CD"
      },
      "source": [
        "plt.figure()\n",
        "# reshape()을 하여 3차원 데이터를 2차원 데이터로 변환.\n",
        "plt.imshow(train_images[7].reshape(28,28))\n",
        "plt.colorbar()\n",
        "plt.grid(False) # gird(): 격자\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQB36MijfJA4"
      },
      "source": [
        "## 합성곱 층 만들기\n",
        "### 아래 6줄의 코드에서 **Conv2D**와 **MaxPooling2D** 층을 쌓는 일반적인 패턴으로 합성곱 층을 정의한다.\n",
        "### **CNN**은 배치(batch) 크기를 제외하고 (이미지 높이, 이미지 너비, 컬러 채널) 크기의 텐서(tensor)를 입력으로 받는다.\n",
        "### **MNIST 데이터**는 (**흑백 이미지이기 떄문에**) **컬러 채널(channel)이 하나**지만 **컬러 이미지는(R, G, B) 세 개의 채널을 가진다.**\n",
        "### 이 예에서는 **MNIST 이미지 포맷인 (28, 28, 1) 크기의 입력을 처리하는 CNN을 정의**한다.\n",
        "### 이 값을 첫 번쨰 층의 **input_shape** 매개변수로 전달한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piX0scxoe8um"
      },
      "source": [
        "model = models.Sequential()\n",
        "# Conv2D와 MaxPooling2D로 층을 쌓는다.\n",
        "# Conv2D와 MaxPooling2D 층의 출력은 (높이, 너비, 채널) 크기의 3D 텐서\n",
        "# relu의 성능이 좋아서 보편적으로 사용한다.\n",
        "model.add(layers.Conv2D(32, (3, 3), activation = \"relu\", input_shape = (28, 28, 1))) # 28 x 28 픽셀, 1개의 채널\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation = \"relu\"))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation = \"relu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz_AayryfRZ2",
        "outputId": "2e522398-161c-424d-e635-930cbe8847f0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R9grLwfgQLg"
      },
      "source": [
        "### 위에서 Conv2D와 MaxPooling2D 층의 출력은 (높이, 너비, 채널) 크기의 3D 텐서이다. 높이와 너비 차원은 네트워크가 깊어질수록 감소하는 경향을 가진다.\n",
        "### Conv2D 층에서 출력 채널의 수는 첫 번쨰 매개변수에 의해 결정된다.(예를들면, 32 또는 64)\n",
        "### 일반적으로 높이와 너비가 줄어듦에 따라 (계산 비용 측면에서) Conv2D 층의 출력 채널을 늘릴 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPEY72gcgwSb"
      },
      "source": [
        "## 마지막에 Dense 층 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZeKp-7Lg0rI"
      },
      "source": [
        "### 모델을 완성하려면 마지막 합성곱 층의 출력 텐서(크기 (3, 3, 64))를 하나 이상의 Dense층에 주입하여 분류를 수행한다.\n",
        "### Dense층은 벡터(1D)를 입력으로 받는데 현재 출력은 3D 텐서이다.\n",
        "### 먼저 3D 출력을 1D로 펼친다. 그다음 하나 이상의 Dense층을 그 위에 추가한다.\n",
        "### MNIST 데이터는 10개의 클래스가 있으므로 마지막에 Dense 층에 10개의 출력과 소프트맥스 활성화 함수를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7vgk7hngNnT"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation = \"relu\"))\n",
        "model.add(layers.Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUZA7REphdza",
        "outputId": "8483379f-d7d5-4835-9bff-87250bb74ba1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txiG3Y0IhkcW"
      },
      "source": [
        "### 여기에서 볼 수 있듯이 두 개의 Dense 층을 통과하기 전에 (3, 3, 64) 출력을 (576) 크기의 벡터로 펼친다.\n",
        "### 3(높이) * 3(너비) * 64(채널) = 576"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRgNO0MThf4T"
      },
      "source": [
        "# 기본 이미지 분류에서 쌓았던 방식\n",
        "# model = keras.Sequential([\n",
        "#                           keras.layers.Flatten(input_shape = (28, 28)),\n",
        "#                           keras.layers.Dense(128, activation = \"relu0\"),\n",
        "#                           keras.layers.Dense(10, activation = \"softmax\")\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJEfaqYajevB",
        "outputId": "29197eeb-284d-40aa-c4c3-03f57987a8d3"
      },
      "source": [
        "model.compile(optimizer = \"adam\",\n",
        "              loss = \"sparse_categorical_crossentropy\",\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 39s 6ms/step - loss: 0.1447 - accuracy: 0.9553\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0462 - accuracy: 0.9853\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0329 - accuracy: 0.9898\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0260 - accuracy: 0.9916\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0203 - accuracy: 0.9932\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0175 - accuracy: 0.9945\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0134 - accuracy: 0.9955\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0116 - accuracy: 0.9961\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0106 - accuracy: 0.9965\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0093 - accuracy: 0.9970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0525c34d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shCHV-jakbzv"
      },
      "source": [
        "### **\"optimizer\"**의 종류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_h_YqQzkiil"
      },
      "source": [
        "from keras import optimizers\n",
        "dir(optimizers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwnC3I_hkWZ0"
      },
      "source": [
        "## 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPM9GK9fjxu2",
        "outputId": "a69612d4-c869-4f3a-dbc4-2090c8a1d6eb"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.0332 - accuracy: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}